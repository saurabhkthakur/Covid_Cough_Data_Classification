{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"Untitled0.ipynb","provenance":[],"collapsed_sections":[]},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"GPU"},"cells":[{"cell_type":"code","metadata":{"id":"tzhKYnvYmhzR","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1622021512318,"user_tz":-330,"elapsed":55159,"user":{"displayName":"Ashish","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhBURgv981KSLCCc9-7tj2zOt9CYwg0gPjDexABzA=s64","userId":"10185821019603866806"}},"outputId":"d85e4745-d080-451b-b6c4-cebda5397030"},"source":["from google.colab import drive\n","drive.mount('/content/drive')"],"execution_count":1,"outputs":[{"output_type":"stream","text":["Mounted at /content/drive\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"85dAhRUVt7mx","executionInfo":{"status":"ok","timestamp":1622021525098,"user_tz":-330,"elapsed":1821,"user":{"displayName":"Ashish","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhBURgv981KSLCCc9-7tj2zOt9CYwg0gPjDexABzA=s64","userId":"10185821019603866806"}}},"source":["import keras.backend as K\n","import tensorflow as tf\n","\n","def categorical_focal_loss(gamma=2.0, alpha=0.25):\n","    \"\"\"\n","    Implementation of Focal Loss from the paper in multiclass classification\n","    Formula:\n","        loss = -alpha*((1-p)^gamma)*log(p)\n","    Parameters:\n","        alpha -- the same as wighting factor in balanced cross entropy\n","        gamma -- focusing parameter for modulating factor (1-p)\n","    Default value:\n","        gamma -- 2.0 as mentioned in the paper\n","        alpha -- 0.25 as mentioned in the paper\n","    \"\"\"\n","    def focal_loss(y_true, y_pred):\n","        # Define epsilon so that the backpropagation will not result in NaN\n","        # for 0 divisor case\n","        epsilon = K.epsilon()\n","        # Add the epsilon to prediction value\n","        #y_pred = y_pred + epsilon\n","        # Clip the prediction value\n","        y_pred = K.clip(y_pred, epsilon, 1.0-epsilon)\n","        # Calculate cross entropy\n","        cross_entropy = -y_true*K.log(y_pred)\n","        # Calculate weight that consists of  modulating factor and weighting factor\n","        weight = alpha * y_true * K.pow((1-y_pred), gamma)\n","        # Calculate focal loss\n","        loss = weight * cross_entropy\n","        # Sum the losses in mini_batch\n","        loss = K.sum(loss, axis=1)\n","        return loss\n","    \n","    return focal_loss\n"],"execution_count":2,"outputs":[]},{"cell_type":"code","metadata":{"id":"UsKdY6Hdm6aP","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1622042286698,"user_tz":-330,"elapsed":1056427,"user":{"displayName":"Ashish","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhBURgv981KSLCCc9-7tj2zOt9CYwg0gPjDexABzA=s64","userId":"10185821019603866806"}},"outputId":"6a647cc2-8452-4f63-83b5-a67b69bdb5bb"},"source":["import numpy as np\n","import keras\n","from keras.models import Sequential\n","from keras.layers import Dense, Dropout, Activation\n","from keras.layers import Embedding\n","from keras.layers import Conv1D, GlobalAveragePooling1D, MaxPooling1D\n","from keras.optimizers import SGD\n","from sklearn.model_selection import train_test_split\n","from keras.callbacks import ModelCheckpoint \n","from datetime import datetime\n","import tensorflow as tf\n","from keras.utils.np_utils import to_categorical\n","from keras.callbacks import ModelCheckpoint \n","from keras.callbacks import EarlyStopping\n","from keras.regularizers import l2\n","from keras.layers import Input\n","from keras.layers import Flatten\n","from keras.layers import Dropout\n","from keras.models import Model\n","\n","from keras.layers.merge import concatenate\n","from imblearn.over_sampling import SMOTE\n","\n","from sklearn.preprocessing import LabelEncoder\n","import os\n","X = np.load('/content/drive/MyDrive/test_co/feat (1).npy')\n","y=np.load('/content/drive/MyDrive/test_co/label.npy')\n","\n","\n","s = SMOTE(k_neighbors=3)\n","X,y=s.fit_resample(X,y)\n","\n","\n","\n","# Split data\n","X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.2,stratify=y, random_state = 233)\n","\n","# Convert label to onehot encoding\n","le = LabelEncoder()\n","\n","y_train = to_categorical(le.fit_transform(y_train))\n","y_test = to_categorical(le.fit_transform(y_test))\n","# y_over = to_categorical(le.fit_transform(y_over))\n","a=len(np.where(y_train==0)[0]) \n","b=len(np.where(y_train==1)[0])\n","c=len(np.where(y_train==2)[0]), \n","# Make 2-dim into 3-dim array for input for model training\n","X_train = np.expand_dims(X_train, axis=2)\n","X_test = np.expand_dims(X_test, axis=2)\n","\n","n_timesteps=X_train.shape[1]\n","n_features = X_train.shape[2]\n","\n","\n","inputs1 = Input(shape=(n_timesteps,n_features))\n","conv1 = Conv1D(filters=1024, kernel_size=7, activation='relu')(inputs1)\n","conv1_2 = Conv1D(filters=512, kernel_size=7, activation='relu')(conv1)\n","pool1 = MaxPooling1D(pool_size=2)(conv1_2)\n","conv1_3 = Conv1D(filters=256, kernel_size=7, activation='relu')(pool1)\n","conv1_4= Conv1D(filters=128, kernel_size=7, activation='relu')(conv1_3)\n","glob_1 = GlobalAveragePooling1D()(conv1_4)\n","drop1 = Dropout(0.4)(glob_1)\n","flat1 = Flatten()(drop1)\n","# head 2\n","\n","inputs2 = Input(shape=(n_timesteps,n_features))\n","conv2 = Conv1D(filters=1024, kernel_size=7, activation='relu')(inputs2)\n","conv2_2 = Conv1D(filters=512, kernel_size=7, activation='relu')(conv2)\n","pool2 = MaxPooling1D(pool_size=2)(conv2_2)\n","conv2_3 = Conv1D(filters=256, kernel_size=7, activation='relu')(pool1)\n","glob_2 = GlobalAveragePooling1D()(conv2_3)\n","drop2 = Dropout(0.4)(glob_2)\n","flat2 = Flatten()(drop2)\n","# head 3\n","inputs3 = Input(shape=(n_timesteps,n_features))\n","conv3 = Conv1D(filters=64, kernel_size=21, activation='relu')(inputs3)\n","drop3 = Dropout(0.5)(conv3)\n","pool3 = MaxPooling1D(pool_size=2)(drop3)\n","flat3 = Flatten()(pool3)\n","# merge\n","merged = concatenate([flat1, flat2, flat3])\n","# interpretation\n","dense1 = Dense(256, activation = 'relu')(merged)\n","dense2 = Dense(128, activation = 'relu')(dense1)\n","dense3 = Dense(64, activation='relu')(dense2)\n","outputs = Dense(3, activation='softmax')(dense3)\n","model = Model(inputs=[inputs1, inputs2, inputs3], outputs=outputs)\n","# save a plot of the model\n","print(model.summary())\n","batch_size=64\n","epochs=100 # Epochs are tunable\n","\n","#\n","lr_schedule = keras.optimizers.schedules.ExponentialDecay(\n","    initial_learning_rate=0.00035,\n","    decay_steps=1000,\n","    decay_rate=0.9)\n","\n","\n","opt = keras.optimizers.Adam(learning_rate=lr_schedule)\n","\n","model.compile(loss=[categorical_focal_loss()],\n","              optimizer=opt,\n","              metrics=['accuracy'])\n","\n","model_file = 'file-train-nb3.hdf5'\n","models_path = '/content/drive/MyDrive/dd/'\n","model_path = os.path.join(models_path, model_file)\n","\n","\n","# Save checkpoints\n","checkpointer = ModelCheckpoint(filepath=model_path, \n","                               verbose=1, \n","                               save_best_only=True)\n","es = EarlyStopping(patience=10)\n","start = datetime.now()\n","history = model.fit([X_train,X_train,X_train], \n","                    y_train, \n","                    batch_size=batch_size, \n","                    epochs=epochs, \n","                    validation_split=1/12.,\n","                    callbacks=[checkpointer,es], \n","                    verbose=1,\n","                    )\n","\n","duration = datetime.now() - start\n","print(\"Training completed in time: \", duration)\n","\n","\n","# Compute Accuracy and Loss\n"],"execution_count":69,"outputs":[{"output_type":"stream","text":["/usr/local/lib/python3.7/dist-packages/sklearn/utils/deprecation.py:87: FutureWarning: Function safe_indexing is deprecated; safe_indexing is deprecated in version 0.22 and will be removed in version 0.24.\n","  warnings.warn(msg, category=FutureWarning)\n","/usr/local/lib/python3.7/dist-packages/sklearn/utils/deprecation.py:87: FutureWarning: Function safe_indexing is deprecated; safe_indexing is deprecated in version 0.22 and will be removed in version 0.24.\n","  warnings.warn(msg, category=FutureWarning)\n"],"name":"stderr"},{"output_type":"stream","text":["Model: \"model_18\"\n","__________________________________________________________________________________________________\n","Layer (type)                    Output Shape         Param #     Connected to                     \n","==================================================================================================\n","input_55 (InputLayer)           [(None, 193, 1)]     0                                            \n","__________________________________________________________________________________________________\n","conv1d_144 (Conv1D)             (None, 187, 1024)    8192        input_55[0][0]                   \n","__________________________________________________________________________________________________\n","conv1d_145 (Conv1D)             (None, 181, 512)     3670528     conv1d_144[0][0]                 \n","__________________________________________________________________________________________________\n","max_pooling1d_54 (MaxPooling1D) (None, 90, 512)      0           conv1d_145[0][0]                 \n","__________________________________________________________________________________________________\n","conv1d_146 (Conv1D)             (None, 84, 256)      917760      max_pooling1d_54[0][0]           \n","__________________________________________________________________________________________________\n","input_57 (InputLayer)           [(None, 193, 1)]     0                                            \n","__________________________________________________________________________________________________\n","conv1d_147 (Conv1D)             (None, 78, 128)      229504      conv1d_146[0][0]                 \n","__________________________________________________________________________________________________\n","conv1d_150 (Conv1D)             (None, 84, 256)      917760      max_pooling1d_54[0][0]           \n","__________________________________________________________________________________________________\n","conv1d_151 (Conv1D)             (None, 173, 64)      1408        input_57[0][0]                   \n","__________________________________________________________________________________________________\n","global_average_pooling1d_36 (Gl (None, 128)          0           conv1d_147[0][0]                 \n","__________________________________________________________________________________________________\n","global_average_pooling1d_37 (Gl (None, 256)          0           conv1d_150[0][0]                 \n","__________________________________________________________________________________________________\n","dropout_56 (Dropout)            (None, 173, 64)      0           conv1d_151[0][0]                 \n","__________________________________________________________________________________________________\n","dropout_54 (Dropout)            (None, 128)          0           global_average_pooling1d_36[0][0]\n","__________________________________________________________________________________________________\n","dropout_55 (Dropout)            (None, 256)          0           global_average_pooling1d_37[0][0]\n","__________________________________________________________________________________________________\n","max_pooling1d_56 (MaxPooling1D) (None, 86, 64)       0           dropout_56[0][0]                 \n","__________________________________________________________________________________________________\n","flatten_54 (Flatten)            (None, 128)          0           dropout_54[0][0]                 \n","__________________________________________________________________________________________________\n","flatten_55 (Flatten)            (None, 256)          0           dropout_55[0][0]                 \n","__________________________________________________________________________________________________\n","flatten_56 (Flatten)            (None, 5504)         0           max_pooling1d_56[0][0]           \n","__________________________________________________________________________________________________\n","concatenate_18 (Concatenate)    (None, 5888)         0           flatten_54[0][0]                 \n","                                                                 flatten_55[0][0]                 \n","                                                                 flatten_56[0][0]                 \n","__________________________________________________________________________________________________\n","dense_72 (Dense)                (None, 256)          1507584     concatenate_18[0][0]             \n","__________________________________________________________________________________________________\n","dense_73 (Dense)                (None, 128)          32896       dense_72[0][0]                   \n","__________________________________________________________________________________________________\n","dense_74 (Dense)                (None, 64)           8256        dense_73[0][0]                   \n","__________________________________________________________________________________________________\n","input_56 (InputLayer)           [(None, 193, 1)]     0                                            \n","__________________________________________________________________________________________________\n","dense_75 (Dense)                (None, 3)            195         dense_74[0][0]                   \n","==================================================================================================\n","Total params: 7,294,083\n","Trainable params: 7,294,083\n","Non-trainable params: 0\n","__________________________________________________________________________________________________\n","None\n","Epoch 1/100\n","282/282 [==============================] - 21s 70ms/step - loss: 0.1488 - accuracy: 0.3745 - val_loss: 0.1137 - val_accuracy: 0.4468\n","\n","Epoch 00001: val_loss improved from inf to 0.11367, saving model to /content/drive/MyDrive/dd/file-train-nb3.hdf5\n","Epoch 2/100\n","282/282 [==============================] - 19s 69ms/step - loss: 0.1128 - accuracy: 0.4630 - val_loss: 0.1070 - val_accuracy: 0.4976\n","\n","Epoch 00002: val_loss improved from 0.11367 to 0.10699, saving model to /content/drive/MyDrive/dd/file-train-nb3.hdf5\n","Epoch 3/100\n","282/282 [==============================] - 19s 67ms/step - loss: 0.1064 - accuracy: 0.5063 - val_loss: 0.1026 - val_accuracy: 0.5257\n","\n","Epoch 00003: val_loss improved from 0.10699 to 0.10263, saving model to /content/drive/MyDrive/dd/file-train-nb3.hdf5\n","Epoch 4/100\n","282/282 [==============================] - 19s 67ms/step - loss: 0.1012 - accuracy: 0.5314 - val_loss: 0.0973 - val_accuracy: 0.5513\n","\n","Epoch 00004: val_loss improved from 0.10263 to 0.09731, saving model to /content/drive/MyDrive/dd/file-train-nb3.hdf5\n","Epoch 5/100\n","282/282 [==============================] - 19s 67ms/step - loss: 0.0944 - accuracy: 0.5655 - val_loss: 0.0926 - val_accuracy: 0.5819\n","\n","Epoch 00005: val_loss improved from 0.09731 to 0.09257, saving model to /content/drive/MyDrive/dd/file-train-nb3.hdf5\n","Epoch 6/100\n","282/282 [==============================] - 19s 67ms/step - loss: 0.0886 - accuracy: 0.6003 - val_loss: 0.0884 - val_accuracy: 0.6100\n","\n","Epoch 00006: val_loss improved from 0.09257 to 0.08843, saving model to /content/drive/MyDrive/dd/file-train-nb3.hdf5\n","Epoch 7/100\n","282/282 [==============================] - 19s 67ms/step - loss: 0.0854 - accuracy: 0.6145 - val_loss: 0.0818 - val_accuracy: 0.6443\n","\n","Epoch 00007: val_loss improved from 0.08843 to 0.08176, saving model to /content/drive/MyDrive/dd/file-train-nb3.hdf5\n","Epoch 8/100\n","282/282 [==============================] - 19s 67ms/step - loss: 0.0786 - accuracy: 0.6474 - val_loss: 0.0784 - val_accuracy: 0.6540\n","\n","Epoch 00008: val_loss improved from 0.08176 to 0.07839, saving model to /content/drive/MyDrive/dd/file-train-nb3.hdf5\n","Epoch 9/100\n","282/282 [==============================] - 19s 67ms/step - loss: 0.0699 - accuracy: 0.6898 - val_loss: 0.0717 - val_accuracy: 0.6736\n","\n","Epoch 00009: val_loss improved from 0.07839 to 0.07172, saving model to /content/drive/MyDrive/dd/file-train-nb3.hdf5\n","Epoch 10/100\n","282/282 [==============================] - 19s 67ms/step - loss: 0.0647 - accuracy: 0.7042 - val_loss: 0.0685 - val_accuracy: 0.7133\n","\n","Epoch 00010: val_loss improved from 0.07172 to 0.06853, saving model to /content/drive/MyDrive/dd/file-train-nb3.hdf5\n","Epoch 11/100\n","282/282 [==============================] - 19s 67ms/step - loss: 0.0591 - accuracy: 0.7251 - val_loss: 0.0602 - val_accuracy: 0.7451\n","\n","Epoch 00011: val_loss improved from 0.06853 to 0.06023, saving model to /content/drive/MyDrive/dd/file-train-nb3.hdf5\n","Epoch 12/100\n","282/282 [==============================] - 19s 67ms/step - loss: 0.0525 - accuracy: 0.7605 - val_loss: 0.0553 - val_accuracy: 0.7555\n","\n","Epoch 00012: val_loss improved from 0.06023 to 0.05526, saving model to /content/drive/MyDrive/dd/file-train-nb3.hdf5\n","Epoch 13/100\n","282/282 [==============================] - 19s 66ms/step - loss: 0.0472 - accuracy: 0.7757 - val_loss: 0.0587 - val_accuracy: 0.7231\n","\n","Epoch 00013: val_loss did not improve from 0.05526\n","Epoch 14/100\n","282/282 [==============================] - 19s 67ms/step - loss: 0.0426 - accuracy: 0.7986 - val_loss: 0.0496 - val_accuracy: 0.7836\n","\n","Epoch 00014: val_loss improved from 0.05526 to 0.04960, saving model to /content/drive/MyDrive/dd/file-train-nb3.hdf5\n","Epoch 15/100\n","282/282 [==============================] - 19s 67ms/step - loss: 0.0390 - accuracy: 0.8149 - val_loss: 0.0499 - val_accuracy: 0.7836\n","\n","Epoch 00015: val_loss did not improve from 0.04960\n","Epoch 16/100\n","282/282 [==============================] - 19s 67ms/step - loss: 0.0347 - accuracy: 0.8391 - val_loss: 0.0441 - val_accuracy: 0.8038\n","\n","Epoch 00016: val_loss improved from 0.04960 to 0.04414, saving model to /content/drive/MyDrive/dd/file-train-nb3.hdf5\n","Epoch 17/100\n","282/282 [==============================] - 19s 67ms/step - loss: 0.0296 - accuracy: 0.8551 - val_loss: 0.0397 - val_accuracy: 0.8203\n","\n","Epoch 00017: val_loss improved from 0.04414 to 0.03969, saving model to /content/drive/MyDrive/dd/file-train-nb3.hdf5\n","Epoch 18/100\n","282/282 [==============================] - 19s 67ms/step - loss: 0.0265 - accuracy: 0.8651 - val_loss: 0.0353 - val_accuracy: 0.8411\n","\n","Epoch 00018: val_loss improved from 0.03969 to 0.03531, saving model to /content/drive/MyDrive/dd/file-train-nb3.hdf5\n","Epoch 19/100\n","282/282 [==============================] - 19s 67ms/step - loss: 0.0255 - accuracy: 0.8706 - val_loss: 0.0355 - val_accuracy: 0.8380\n","\n","Epoch 00019: val_loss did not improve from 0.03531\n","Epoch 20/100\n","282/282 [==============================] - 19s 67ms/step - loss: 0.0218 - accuracy: 0.8923 - val_loss: 0.0387 - val_accuracy: 0.8160\n","\n","Epoch 00020: val_loss did not improve from 0.03531\n","Epoch 21/100\n","282/282 [==============================] - 19s 67ms/step - loss: 0.0223 - accuracy: 0.8892 - val_loss: 0.0312 - val_accuracy: 0.8478\n","\n","Epoch 00021: val_loss improved from 0.03531 to 0.03125, saving model to /content/drive/MyDrive/dd/file-train-nb3.hdf5\n","Epoch 22/100\n","282/282 [==============================] - 19s 67ms/step - loss: 0.0183 - accuracy: 0.9048 - val_loss: 0.0326 - val_accuracy: 0.8582\n","\n","Epoch 00022: val_loss did not improve from 0.03125\n","Epoch 23/100\n","282/282 [==============================] - 19s 67ms/step - loss: 0.0177 - accuracy: 0.9116 - val_loss: 0.0300 - val_accuracy: 0.8698\n","\n","Epoch 00023: val_loss improved from 0.03125 to 0.02997, saving model to /content/drive/MyDrive/dd/file-train-nb3.hdf5\n","Epoch 24/100\n","282/282 [==============================] - 19s 67ms/step - loss: 0.0158 - accuracy: 0.9206 - val_loss: 0.0319 - val_accuracy: 0.8612\n","\n","Epoch 00024: val_loss did not improve from 0.02997\n","Epoch 25/100\n","282/282 [==============================] - 19s 67ms/step - loss: 0.0137 - accuracy: 0.9329 - val_loss: 0.0290 - val_accuracy: 0.8716\n","\n","Epoch 00025: val_loss improved from 0.02997 to 0.02898, saving model to /content/drive/MyDrive/dd/file-train-nb3.hdf5\n","Epoch 26/100\n","282/282 [==============================] - 19s 67ms/step - loss: 0.0133 - accuracy: 0.9367 - val_loss: 0.0281 - val_accuracy: 0.8661\n","\n","Epoch 00026: val_loss improved from 0.02898 to 0.02814, saving model to /content/drive/MyDrive/dd/file-train-nb3.hdf5\n","Epoch 27/100\n","282/282 [==============================] - 19s 67ms/step - loss: 0.0132 - accuracy: 0.9346 - val_loss: 0.0294 - val_accuracy: 0.8704\n","\n","Epoch 00027: val_loss did not improve from 0.02814\n","Epoch 28/100\n","282/282 [==============================] - 19s 67ms/step - loss: 0.0119 - accuracy: 0.9374 - val_loss: 0.0271 - val_accuracy: 0.8820\n","\n","Epoch 00028: val_loss improved from 0.02814 to 0.02715, saving model to /content/drive/MyDrive/dd/file-train-nb3.hdf5\n","Epoch 29/100\n","282/282 [==============================] - 19s 67ms/step - loss: 0.0096 - accuracy: 0.9521 - val_loss: 0.0285 - val_accuracy: 0.8808\n","\n","Epoch 00029: val_loss did not improve from 0.02715\n","Epoch 30/100\n","282/282 [==============================] - 19s 67ms/step - loss: 0.0087 - accuracy: 0.9577 - val_loss: 0.0290 - val_accuracy: 0.8845\n","\n","Epoch 00030: val_loss did not improve from 0.02715\n","Epoch 31/100\n","282/282 [==============================] - 19s 67ms/step - loss: 0.0079 - accuracy: 0.9622 - val_loss: 0.0268 - val_accuracy: 0.8924\n","\n","Epoch 00031: val_loss improved from 0.02715 to 0.02677, saving model to /content/drive/MyDrive/dd/file-train-nb3.hdf5\n","Epoch 32/100\n","282/282 [==============================] - 19s 67ms/step - loss: 0.0078 - accuracy: 0.9621 - val_loss: 0.0279 - val_accuracy: 0.8833\n","\n","Epoch 00032: val_loss did not improve from 0.02677\n","Epoch 33/100\n","282/282 [==============================] - 19s 67ms/step - loss: 0.0088 - accuracy: 0.9592 - val_loss: 0.0260 - val_accuracy: 0.8900\n","\n","Epoch 00033: val_loss improved from 0.02677 to 0.02602, saving model to /content/drive/MyDrive/dd/file-train-nb3.hdf5\n","Epoch 34/100\n","282/282 [==============================] - 19s 67ms/step - loss: 0.0065 - accuracy: 0.9678 - val_loss: 0.0275 - val_accuracy: 0.8918\n","\n","Epoch 00034: val_loss did not improve from 0.02602\n","Epoch 35/100\n","282/282 [==============================] - 19s 67ms/step - loss: 0.0059 - accuracy: 0.9709 - val_loss: 0.0286 - val_accuracy: 0.8973\n","\n","Epoch 00035: val_loss did not improve from 0.02602\n","Epoch 36/100\n","282/282 [==============================] - 19s 67ms/step - loss: 0.0060 - accuracy: 0.9704 - val_loss: 0.0281 - val_accuracy: 0.8918\n","\n","Epoch 00036: val_loss did not improve from 0.02602\n","Epoch 37/100\n","282/282 [==============================] - 19s 67ms/step - loss: 0.0054 - accuracy: 0.9749 - val_loss: 0.0266 - val_accuracy: 0.8998\n","\n","Epoch 00037: val_loss did not improve from 0.02602\n","Epoch 38/100\n","282/282 [==============================] - 19s 67ms/step - loss: 0.0057 - accuracy: 0.9734 - val_loss: 0.0254 - val_accuracy: 0.9059\n","\n","Epoch 00038: val_loss improved from 0.02602 to 0.02536, saving model to /content/drive/MyDrive/dd/file-train-nb3.hdf5\n","Epoch 39/100\n","282/282 [==============================] - 19s 67ms/step - loss: 0.0044 - accuracy: 0.9781 - val_loss: 0.0257 - val_accuracy: 0.9089\n","\n","Epoch 00039: val_loss did not improve from 0.02536\n","Epoch 40/100\n","282/282 [==============================] - 19s 67ms/step - loss: 0.0044 - accuracy: 0.9797 - val_loss: 0.0289 - val_accuracy: 0.9028\n","\n","Epoch 00040: val_loss did not improve from 0.02536\n","Epoch 41/100\n","282/282 [==============================] - 19s 67ms/step - loss: 0.0043 - accuracy: 0.9804 - val_loss: 0.0252 - val_accuracy: 0.9095\n","\n","Epoch 00041: val_loss improved from 0.02536 to 0.02520, saving model to /content/drive/MyDrive/dd/file-train-nb3.hdf5\n","Epoch 42/100\n","282/282 [==============================] - 19s 67ms/step - loss: 0.0036 - accuracy: 0.9847 - val_loss: 0.0276 - val_accuracy: 0.9040\n","\n","Epoch 00042: val_loss did not improve from 0.02520\n","Epoch 43/100\n","282/282 [==============================] - 19s 67ms/step - loss: 0.0037 - accuracy: 0.9823 - val_loss: 0.0271 - val_accuracy: 0.9095\n","\n","Epoch 00043: val_loss did not improve from 0.02520\n","Epoch 44/100\n","282/282 [==============================] - 19s 67ms/step - loss: 0.0035 - accuracy: 0.9833 - val_loss: 0.0261 - val_accuracy: 0.9083\n","\n","Epoch 00044: val_loss did not improve from 0.02520\n","Epoch 45/100\n","282/282 [==============================] - 19s 67ms/step - loss: 0.0031 - accuracy: 0.9864 - val_loss: 0.0276 - val_accuracy: 0.8955\n","\n","Epoch 00045: val_loss did not improve from 0.02520\n","Epoch 46/100\n","282/282 [==============================] - 19s 67ms/step - loss: 0.0028 - accuracy: 0.9885 - val_loss: 0.0285 - val_accuracy: 0.9059\n","\n","Epoch 00046: val_loss did not improve from 0.02520\n","Epoch 47/100\n","282/282 [==============================] - 19s 67ms/step - loss: 0.0028 - accuracy: 0.9861 - val_loss: 0.0284 - val_accuracy: 0.9095\n","\n","Epoch 00047: val_loss did not improve from 0.02520\n","Epoch 48/100\n","282/282 [==============================] - 19s 67ms/step - loss: 0.0027 - accuracy: 0.9864 - val_loss: 0.0292 - val_accuracy: 0.9077\n","\n","Epoch 00048: val_loss did not improve from 0.02520\n","Epoch 49/100\n","282/282 [==============================] - 19s 67ms/step - loss: 0.0025 - accuracy: 0.9889 - val_loss: 0.0253 - val_accuracy: 0.9199\n","\n","Epoch 00049: val_loss did not improve from 0.02520\n","Epoch 50/100\n","282/282 [==============================] - 19s 67ms/step - loss: 0.0026 - accuracy: 0.9881 - val_loss: 0.0293 - val_accuracy: 0.9095\n","\n","Epoch 00050: val_loss did not improve from 0.02520\n","Epoch 51/100\n","282/282 [==============================] - 19s 67ms/step - loss: 0.0024 - accuracy: 0.9889 - val_loss: 0.0281 - val_accuracy: 0.9108\n","\n","Epoch 00051: val_loss did not improve from 0.02520\n","Training completed in time:  0:17:35.308917\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"hkjqi9FKnVZ_","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1622042298731,"user_tz":-330,"elapsed":4812,"user":{"displayName":"Ashish","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhBURgv981KSLCCc9-7tj2zOt9CYwg0gPjDexABzA=s64","userId":"10185821019603866806"}},"outputId":"0cf3f5cf-82c2-403d-927a-043fb0b004cf"},"source":["score, acc = model.evaluate([X_test,X_test,X_test], y_test, batch_size=8)"],"execution_count":70,"outputs":[{"output_type":"stream","text":["614/614 [==============================] - 4s 7ms/step - loss: 0.0290 - accuracy: 0.9126\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"FTaW2so0nYm0","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1622042306718,"user_tz":-330,"elapsed":2763,"user":{"displayName":"Ashish","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhBURgv981KSLCCc9-7tj2zOt9CYwg0gPjDexABzA=s64","userId":"10185821019603866806"}},"outputId":"791df4bf-086f-47c0-92b3-6ac22b576fcf"},"source":["from sklearn.metrics import confusion_matrix,f1_score\n","y_probs = model.predict([X_test,X_test,X_test], verbose=0)\n","yhat_probs = np.argmax(y_probs, axis=1)\n","\n","confusion_matrix(y_test.argmax(axis=1), y_probs.argmax(axis=1))"],"execution_count":71,"outputs":[{"output_type":"execute_result","data":{"text/plain":["array([[1413,   97,  126],\n","       [  19, 1615,    2],\n","       [ 179,    6, 1451]])"]},"metadata":{"tags":[]},"execution_count":71}]},{"cell_type":"code","metadata":{"id":"aTLg_5Jjttvo","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1622042311201,"user_tz":-330,"elapsed":640,"user":{"displayName":"Ashish","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhBURgv981KSLCCc9-7tj2zOt9CYwg0gPjDexABzA=s64","userId":"10185821019603866806"}},"outputId":"f06488ac-5afe-4519-889b-031df7c56cf6"},"source":["f1_score(y_test.argmax(axis=1), y_probs.argmax(axis=1),average='micro')"],"execution_count":72,"outputs":[{"output_type":"execute_result","data":{"text/plain":["0.9125916870415648"]},"metadata":{"tags":[]},"execution_count":72}]},{"cell_type":"markdown","metadata":{"id":"ovEAwdoJxP4Q"},"source":["lr_schedule = tf.keras.optimizers.schedules.ExponentialDecay(\n","    initial_learning_rate,\n","    decay_steps=100000,\n","    decay_rate=0.96,\n","    staircase=True)"]},{"cell_type":"code","metadata":{"id":"b9BbBlRInQcM","executionInfo":{"status":"ok","timestamp":1622032213921,"user_tz":-330,"elapsed":422,"user":{"displayName":"Ashish","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhBURgv981KSLCCc9-7tj2zOt9CYwg0gPjDexABzA=s64","userId":"10185821019603866806"}}},"source":["model.save_weights(\"/content/drive/MyDrive/test_co/aks.h5\")"],"execution_count":37,"outputs":[]}]}